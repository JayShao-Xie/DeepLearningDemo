{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 任务介绍\n",
    "**猫狗图像二分类问题**，本次实验基于[Pytorch](https://pytorch.org/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 引入头文件"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torchvision.utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 准备数据集，将数据集划分为训练集、验证集和测试集\n",
    "源数据集[来源](https://www.kaggle.com/competitions/dogs-vs-cats/data)，这是一个包含25000张图像的**猫狗**数据集。本次实验采用的数据集是源数据集的子集。\n",
    "* 训练集：每个类别均有1000张图像\n",
    "* 验证集：每个类别均有500张图像\n",
    "* 测试集：每个类别均有500张图像"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "original_dataset_dir = './dataset/original_data/train'\n",
    "\n",
    "base_dir = './dataset'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images: 1000\n",
      "total training dog images: 1000\n",
      "total validation cat images: 500\n",
      "total validation dog images: 500\n",
      "total test cat images: 500\n",
      "total test dog images: 500\n"
     ]
    }
   ],
   "source": [
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "\n",
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"数据预处理\n",
    "Dataset - Pytorch使用的数据集的创建,传递给DataLoader\n",
    "DataLoader - 迭代产生训练数据提供给模型\n",
    "\"\"\"\n",
    "\n",
    "dataset_dir = './dataset'\n",
    "\n",
    "class Imageset(Dataset):\n",
    "    def __init__(self, root, mode):\n",
    "        # Todo\n",
    "        # 1. Initialize file path or list of file names.\n",
    "\n",
    "        super(Imageset, self).__init__()\n",
    "\n",
    "        assert mode in ['train', 'validation', 'test']\n",
    "        self.image_dir = os.path.join(root, mode)\n",
    "\n",
    "        \"\"\"Todo: 我们可以在这里进行数据增强\n",
    "        if mode == 'train':\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomResizedCrop((150, 150), (1.0, 1.12), interpolation=Image.BICUBIC),  # 随机裁剪，然后对裁剪得到的图像缩放为同一大小\n",
    "                transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((150, 150)), transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "        \"\"\"\n",
    "        if mode == 'train':\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((150, 150)), transforms.ToTensor(),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((150, 150)), transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "        self.image_list = []\n",
    "        self.target_list = []\n",
    "\n",
    "        for i, category in enumerate(os.listdir(self.image_dir)):\n",
    "            for name in os.listdir(os.path.join(self.image_dir, category)):\n",
    "                self.image_list.append(os.path.join(self.image_dir, category, name))\n",
    "                self.target_list.append(i)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Todo\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "\n",
    "        path = self.image_list[index]\n",
    "        image = self.transform(Image.open(path).convert('RGB'))\n",
    "        label = self.target_list[index]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "\n",
    "train_dataset = Imageset(dataset_dir, 'train')\n",
    "validation_dataset = Imageset(dataset_dir, 'validation')\n",
    "test_dataset = Imageset(dataset_dir, 'test')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=20, shuffle=True, num_workers=8)\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=20, shuffle=False, num_workers=8, drop_last=False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False, num_workers=8, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 构建网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class convnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convnet, self).__init__()\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=6272, out_features=512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_1_out = self.conv_1(x)\n",
    "        conv_2_out = self.conv_2(conv_1_out)\n",
    "        x = self.relu(self.fc1(self.flatten(conv_2_out)))\n",
    "        return conv_1_out, conv_2_out, self.sigmoid(self.fc2(x))\n",
    "\n",
    "model = convnet()\n",
    "model = model.cuda()\n",
    "\n",
    "\"\"\"用于测试网络是否可行\n",
    "model = convnet()\n",
    "x = torch.randn((4, 3, 150, 150))\n",
    "output = model(x)\n",
    "print(output.size())\n",
    "print(output)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"使用预训练的网络(vgg16)来提取特征，只训练最后的分类器\n",
    "from torchvision.models.vgg import vgg16\n",
    "\n",
    "class convnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convnet, self).__init__()\n",
    "        self.vgg = vgg16(pretrained=True).features\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=4 * 4 * 512, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.flatten(self.vgg(x)))\n",
    "\n",
    "optimizer = optim.RMSprop(model.classifier.parameters(), lr=learning_rate)\n",
    "outputs = model(images)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "loss_fn = nn.BCELoss()\n",
    "# 优化器\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 创建存放模型的文件夹\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.mkdir('./checkpoints')\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_validation_step = 0\n",
    "# 训练的轮数\n",
    "epochs = 30\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"--------第 {} 轮训练开始--------\".format(epoch + 1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    model.train()\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.cuda(), labels.cuda().unsqueeze(-1).to(torch.float)\n",
    "        _, _, outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # 优化器调优\n",
    "        optimizer.zero_grad()  # 清空过往梯度\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数: {}, Loss: {}\".format(total_train_step, loss.item()))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    # 验证步骤开始\n",
    "    model.eval()\n",
    "    total_validation_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    # 表明当前计算不需要反向传播，使用之后，强制后边的内容不进行计算图的构建\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_dataloader:\n",
    "            images, labels = images.cuda(), labels.cuda().unsqueeze(-1).to(torch.float)\n",
    "            _, _, outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_validation_loss = total_validation_loss + loss.item()\n",
    "            predicts = torch.where(outputs > 0.5, 1, 0)\n",
    "            accuracy = (predicts == labels.to(torch.long)).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "\n",
    "    print(\"整体验证集上的Loss: {}\".format(total_validation_loss))\n",
    "    print(\"整体验证集上的正确率: {}\".format(total_accuracy / len(validation_dataset)))\n",
    "    writer.add_scalar(\"validation_loss\", total_validation_loss, total_validation_step)\n",
    "    writer.add_scalar(\"validation_accuracy\", total_accuracy / len(validation_dataset), total_validation_step)\n",
    "    total_validation_step = total_validation_step + 1\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join('./checkpoints', \"model_{}.pth\".format(epoch + 1)))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 测试 & 可视化中间特征"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义函数，随机从0-end的一个序列中抽取size个不同的数\n",
    "def random_num(size, end):\n",
    "    range_ls = [i for i in range(end)]\n",
    "    num_ls = []\n",
    "    for i in range(size):\n",
    "        num = random.choice(range_ls)\n",
    "        range_ls.remove(num)\n",
    "        num_ls.append(num)\n",
    "    return num_ls\n",
    "\n",
    "model = convnet()\n",
    "model = model.cuda()\n",
    "# 加载先前保留的参数\n",
    "model.load_state_dict(torch.load('./checkpoints/model_20.pth'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, (images, _) in enumerate(test_dataloader):\n",
    "        images = images.cuda()\n",
    "        features, _, outputs = model(images)\n",
    "        predicts = torch.where(outputs > 0.5, 1, 0)\n",
    "        print(predicts)\n",
    "        # 可视化第一张图的低级特征\n",
    "        if i == 0:\n",
    "            torchvision.utils.save_image(images, f'{i}.jpg')\n",
    "            features = features.data.squeeze(0).cpu()\n",
    "            # 随机选取25个通道的特征图\n",
    "            channel_num = random_num(25, features.shape[0])\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            for index, channel in enumerate(channel_num):\n",
    "                ax = plt.subplot(5, 5, index + 1, )\n",
    "                plt.imshow(features[channel, :, :])\n",
    "            plt.savefig(f\"feature_{i}.jpg\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
